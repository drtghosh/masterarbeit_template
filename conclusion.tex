\chapter{Conclusion}\label{ch:conclusion}
\section{Summary}
This work researched and implemented several possible methods for quantifying uncertainty for surface reconstruction from unoriented partial point clouds. To the best of our knowledge, this type of problem has not been addressed in any previous works. 

The existing point cloud completion methods can be modified to generate multiple possible complete clouds, which then can be used to empirically estimate the distribution over the reconstructed surface. Various methods for generating multiple clouds from the input partial cloud were implemented. While DropConnect-based methods were simpler to implement and faster to train, the generated clouds often lack diversity or consistency. Dropout-based methods were also simple to implement, offering a better approximation of the ground truth and greater diversity, albeit in a limited manner. The ensemble of generators is also sometimes not diverse enough, depending on the way the ensemble is constructed. However, the results were more consistent than those of DropConnect generations. Unfortunately, the ensemble method is not scalable as the number of parameters increases linearly with the number of models, resulting in high memory and time complexity. Implicit generative models yielded the most promising results, generating diverse and consistent completions with minimal added complexity in network structures.

The same idea can also be applied to implicit representation learning from unoriented point clouds. Although such methods are typically designed for individual point clouds, they can be modified to learn shape spaces conditioned on observed partial clouds. Considering the results of the point cloud completion method, only the implicit generative method was implemented in this setting. Unfortunately, due to numerous bottlenecks in learning such a complex model, the original approach could not be successfully implemented. 

Finally, motivated by the numerous works that attempt to quantify the uncertainty of surface reconstruction using a Gaussian process, a conditional Gaussian process was employed to model the implicit function of the surface based on partial cloud input. Gaussian processes are primarily applied to regression tasks. Therefore, in most previous methods, the implicit representations are learned via some real-valued supervision. However, only observed points lying on the surface (manifold points) are available in our setting, and directly applying a GP is not suitable in this case. An attempt was first made to learn a mapping or embedding for both manifold and non-manifold points using various criteria, such as log-likelihood or contrastive loss, before applying a GP to model the implicit function. Unfortunately, numeric precision-related issues rendered it futile to use both posterior and marginal likelihood as criteria for learning. Although the learned embeddings were shown to be meaningful, and the GP posterior mean-based implicit function reconstructed the surface quite well, the uncertainty values were often not meaningful, either due to numerical issues or a lack of proper supervision from non-manifold points.



\section{Future Work}
The proposed methods provided a solid foundation for future research in the field of uncertainty quantification for surface reconstruction from incomplete or sparse point clouds. The limited nature of available data in real-time and real-world applications related to scanned point clouds makes the task extremely challenging. Therefore, through this initial work, it was only possible to lay some groundwork for an exciting and less-explored research topic. The methods experimented with can be further improved with more time and resources. The possible improvements that can be investigated are discussed below.

    \subsection{Improving Proposed Methods}
        \subsubsection{Improvements to Point Cloud Completion}
        While there is limited room for experimentation with dropout-based methods, ensemble-based approaches can be further improved in terms of diversity and computational costs. Different methods for constructing an ensemble that can produce more diverse outputs can be explored. Various approaches to avoid the expensive computation and memory usage in ensemble methods, as discussed in Section~\ref{Deepsemble}, can be implemented and compared.
        \newline
        
        With advancements in deep learning-based models, several new architectures have been proposed recently, which perform the point cloud completion task with better accuracy. Many such methods are based on generative modeling, where the concept of one-to-many mappings — necessary for generating multiple possible outputs — is inherent. Therefore, the idea of empirically estimating the uncertainty can be extended with the simple modification proposed for implicit generative models in this work. Energy-based models~\cite{EBResLT}, denoising diffusion probabilistic models~\cite{DDPM}, flow matching~\cite{PSF}, and other recent advanced methods in generative modeling can be employed to replace our simpler architecture to learn the point cloud completion with uncertainty.
    
        \subsubsection{Alternative Uncertain Implicit Representation Learning}
        Due to time and resource constraints, a simplified network was used for conditional implicit representation learning for a shape space. Moreover, only implicit generation was employed to produce multiple implicit functions. Therefore, further experiments following the same procedure can be performed with more complex and suitable network architectures described in~\cite{DiGS} or~\cite{NeuralHessian}. Another generative modeling approach, rather than simply injecting noise while learning to generate output or regularizing the noise space, can help improve the results.
    
        \subsubsection{Modified Gaussian Process-based Methods}
        Gaussian process methods have a bottleneck due to the computational cost, which is a result of the cubic complexity of the matrix inversion. Gaussian processes are thus not scalable in high-dimensional settings, such as the one presented in this work. Several recent works have proposed various approaches to address the computational bottleneck of GP. Such approaches include sparse approximation of the original covariance matrix, or computing multiple local GPs according to some division of space bounding the 3D objects. Further research can be conducted to address the issue of the covariance matrix by introducing a separate prior for the covariance function.

    \subsection{Future Extensions and Applications}
    In this work, all the experiments were conducted with the assumption that no information about the normals was available. Although not completely reliable, normal information can be extracted from the available data or computed during scanning. A future interesting avenue of research would be working with partial or sparse point clouds that include normal information and incorporating them into the methods experimented with, making some modifications. 
    \newline

    The scope of this work can be extended to several applications related to 3D objects, where uncertainty is a crucial factor in decision-making. Collision detection, path planning, or next-view planning are some interesting applications where the proposed methods can be rigorously tested. Training with more complex real-life datasets can provide us with much more insight into the limitations of the methods used and offer new ideas to further improve them.