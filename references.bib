@article{IMLE,
       author = {{Li}, Ke and {Malik}, Jitendra},
        title = "{Implicit Maximum Likelihood Estimation}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
         year = 2018,
        month = sep,
          doi = {10.48550/arXiv.1809.09087},
archivePrefix = {arXiv},
       eprint = {1809.09087},
 primaryClass = {cs.LG},
}

@article{PCCIMLE,
  title={Multimodal Shape Completion via Implicit Maximum Likelihood Estimation},
  author={Himanshu Arora and Saurabh Mishra and Shichong Peng and Ke Li and Ali Mahdavi-Amiri},
  journal={2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
  year={2022},
  pages={2957-2966},
}


@InProceedings{AdaIMLE,
  title = 	 {Adaptive {IMLE} for Few-shot Pretraining-free Generative Modelling},
  author =       {Aghabozorgi, Mehran and Peng, Shichong and Li, Ke},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {248--264},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  abstract = 	 {Despite their success on large datasets, GANs have been difficult to apply in the few-shot setting, where only a limited number of training examples are provided. Due to mode collapse, GANs tend to ignore some training examples, causing overfitting to a subset of the training dataset, which is small in the first place. A recent method called Implicit Maximum Likelihood Estimation (IMLE) is an alternative to GAN that tries to address this issue. It uses the same kind of generators as GANs but trains it with a different objective that encourages mode coverage. However, the theoretical guarantees of IMLE hold under a restrictive condition that the optimal likelihood at all data points is the same. In this paper, we present a more generalized formulation of IMLE which includes the original formulation as a special case, and we prove that the theoretical guarantees hold under weaker conditions. Using this generalized formulation, we further derive a new algorithm, which we dub Adaptive IMLE, which can adapt to the varying difficulty of different training examples. We demonstrate on multiple few-shot image synthesis datasets that our method significantly outperforms existing methods. Our code is available at https://github.com/mehranagh20/AdaIMLE.}
}

@inproceedings{PCN,
  title     = {PCN: Point Completion Network},
  author    = {Yuan, Wentao and Khot, Tejas and Held, David and Mertz, Christoph and Hebert, Martial},
  booktitle = {2018 International Conference on 3D Vision (3DV)},
  pages     = {728--737},
  year      = {2018}
}

@inproceedings{PoinTr,
  title={PoinTr: Diverse Point Cloud Completion with Geometry-Aware Transformers},
  author={Yu, Xumin and Rao, Yongming and Wang, Ziyi and Liu, Zuyan and Lu, Jiwen and Zhou, Jie},
  booktitle={ICCV},
  year={2021}
}

@article{PointAttN,
   title={PointAttN: You Only Need Attention for Point Cloud Completion},
   volume={38}, 
   DOI={10.1609/aaai.v38i6.28356}, 
   number={6}, 
   journal={Proceedings of the AAAI Conference on Artificial Intelligence},
   author={Wang, Jun and Cui, Ying and Guo, Dongyan and Li, Junxia and Liu, Qingshan and Shen, Chunhua},
   year={2024},
   month={Mar.},
   pages={5472-5480}
}

@INPROCEEDINGS {P2C,
author = { Cui, Ruikai and Qiu, Shi and Anwar, Saeed and Liu, Jiawei and Xing, Chaoyue and Zhang, Jing and Barnes, Nick },
booktitle = { 2023 IEEE/CVF International Conference on Computer Vision (ICCV) },
title = {{ P2C: Self-Supervised Point Cloud Completion from Single Partial Clouds }},
year = {2023},
volume = {},
ISSN = {},
pages = {14305-14314},
abstract = { Point cloud completion aims to recover the complete shape based on a partial observation. Existing methods require either complete point clouds or multiple partial observations of the same object for learning. In contrast to previous approaches, we present Partial2Complete (P2C), the first self-supervised framework that completes point cloud objects using training samples consisting of only a single incomplete point cloud per object. Specifically, our framework groups incomplete point clouds into local patches as input and predicts masked patches by learning prior information from different partial objects. We also propose Region-Aware Chamfer Distance to regularize shape mismatch without limiting completion capability, and devise the Normal Consistency Constraint to incorporate a local planarity assumption, encouraging the recovered shape surface to be continuous and complete. In this way, P2C no longer needs multiple observations or complete point clouds as ground truth. Instead, structural cues are learned from a category-specific dataset to complete partial point clouds of objects. We demonstrate the effectiveness of our approach on both synthetic ShapeNet data and real-world ScanNet data, showing that P2C produces comparable results to methods trained with complete shapes, and outperforms methods learned with multiple partial observations. Code is available at https://github.com/CuiRuikai/Partial2Complete. },
keywords = {Point cloud compression;Training;Computer vision;Limiting;Codes;Shape;Computational modeling},
doi = {10.1109/ICCV51070.2023.01320},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month =Oct}

@article{VarPCN,
  title={Variational Relational Point Completion Network},
  author={Pan, Liang and Chen, Xinyi and Cai, Zhongang and Zhang, Junzhe and Zhao, Haiyu and Yi, Shuai and Liu, Ziwei},
  journal={arXiv preprint arXiv:2104.10154},
  year={2021}
}

@article{PCNSkip,
  author       = {Xin Wen and
                  Tianyang Li and
                  Zhizhong Han and
                  Yu{-}Shen Liu},
  title        = {Point Cloud Completion by Skip-attention Network with Hierarchical
                  Folding},
  journal      = {CoRR},
  volume       = {abs/2005.03871},
  year         = {2020},
  eprinttype    = {arXiv},
  eprint       = {2005.03871},
  timestamp    = {Fri, 15 Nov 2024 15:28:13 +0100},
}

@ARTICLE{Snowflake,
  author={Xiang, Peng and Wen, Xin and Liu, Yu-Shen and Cao, Yan-Pei and Wan, Pengfei and Zheng, Wen and Han, Zhizhong},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Snowflake Point Deconvolution for Point Cloud Completion and Generation With Skip-Transformer}, 
  year={2023},
  volume={45},
  number={5},
  pages={6320-6338},
  doi={10.1109/TPAMI.2022.3217161}}

@INPROCEEDINGS{HyperPocket,
  author={Spurek, P. and Kasymov, A. and Mazur, M. and Janik, D. and Tadeja, S.K. and Struski, Ł. and Tabor, J. and Trzciński, T.},
  booktitle={2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={HyperPocket: Generative Point Cloud Completion}, 
  year={2022},
  volume={},
  number={},
  pages={6848-6853},
  keywords={Point cloud compression;Computer vision;Three-dimensional displays;Computer architecture;Task analysis;Intelligent robots},
  doi={10.1109/IROS47612.2022.9981829}}

@inproceedings{CGAN,
author = {Wu, Rundi and Chen, Xuelin and Zhuang, Yixin and Chen, Baoquan},
title = {Multimodal Shape Completion via Conditional Generative Adversarial Networks},
year = {2020},
isbn = {978-3-030-58547-1},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
doi = {10.1007/978-3-030-58548-8_17},
abstract = {Several deep learning methods have been proposed for completing partial data from shape acquisition setups, i.e., filling the regions that were missing in the shape. These methods, however, only complete the partial shape with a single output, ignoring the ambiguity when reasoning the missing geometry. Hence, we pose a multi-modal shape completion problem, in which we seek to complete the partial shape with multiple outputs by learning a one-to-many mapping. We develop the first multimodal shape completion method that completes the partial shape via conditional generative modeling, without requiring paired training data. Our approach distills the ambiguity by conditioning the completion on a learned multimodal distribution of possible results. We extensively evaluate the approach on several datasets that contain varying forms of shape incompleteness, and compare among several baseline methods and variants of our methods qualitatively and quantitatively, demonstrating the merit of our method in completing partial shapes with both diversity and quality.},
booktitle = {Computer Vision – ECCV 2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings, Part IV},
pages = {281–296},
numpages = {16},
keywords = {Shape completion, Multimodal mapping, Conditional generative adversarial network},
location = {Glasgow, United Kingdom}
}

@inproceedings{EBResLT,
author    = {Ruikai Cui and Shi Qiu and Saeed Anwar and Jing Zhang and Nick Barnes},
title     = {Energy-Based Residual Latent Transport for Unsupervised Point Cloud Completion},
booktitle = {33rd British Machine Vision Conference 2022, {BMVC} 2022, London, UK, November 21-24, 2022},
publisher = {{BMVA} Press},
year      = {2022},
}

@INPROCEEDINGS{ModeCollapseGAN,
  author={Kossale, Youssef and Airaj, Mohammed and Darouichi, Aziz},
  booktitle={2022 8th International Conference on Optimization and Applications (ICOA)}, 
  title={Mode Collapse in Generative Adversarial Networks: An Overview}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  keywords={Training;Computational modeling;Generative adversarial networks;Unsupervised learning;Tuning;Optimization;GANs;Mode collapse;Generative models;Unsupervised learning},
  doi={10.1109/ICOA55659.2022.9934291}
}

@article{Hypernet,
  author       = {David Ha and
                  Andrew M. Dai and
                  Quoc V. Le},
  title        = {HyperNetworks},
  journal      = {CoRR},
  volume       = {abs/1609.09106},
  year         = {2016},
  eprinttype    = {arXiv},
  eprint       = {1609.09106},
  timestamp    = {Mon, 13 Aug 2018 16:48:51 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/HaDL16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@ARTICLE{PCHypernet,
  author={Spurek, Przemyslaw and Zieba, Maciej and Tabor, Jacek and Trzcinski, Tomasz},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={General Hypernetwork Framework for Creating 3D Point Clouds}, 
  year={2022},
  volume={44},
  number={12},
  pages={9995-10008},
  doi={10.1109/TPAMI.2021.3131131}
}

@article{EBM,
author = {Ackley, David H. and Hinton, Geoffrey E. and Sejnowski, Terrence J.},
title = {A Learning Algorithm for Boltzmann Machines},
journal = {Cognitive Science},
volume = {9},
number = {1},
pages = {147-169},
doi = {https://doi.org/10.1207/s15516709cog0901\_7},
abstract = {The computational power of massively parallel networks of simple processing elements resides in the communication bandwidth provided by the hardware connections between elements. These connections can allow a significant fraction of the knowledge of the system to be applied to an instance of a problem in a very short time. One kind of computation for which massively parallel networks appear to be well suited is large constraint satisfaction searches, but to use the connections efficiently two conditions must be met: First, a search technique that is suitable for parallel networks must be found. Second, there must be some way of choosing internal representations which allow the preexisting hardware connections to be used efficiently for encoding the constraints in the domain being searched. We describe a general parallel search method, based on statistical mechanics, and we show how it leads to a general learning rule for modifying the connection strengths so as to incorporate knowledge about a task domain in an efficient way. We describe some simple examples in which the learning algorithm creates internal representations that are demonstrably the most efficient way of using the preexisting connectivity structure.},
year = {1985}
}

@article{Hungarian,
author = {Kuhn, H. W.},
title = {The Hungarian method for the assignment problem},
journal = {Naval Research Logistics Quarterly},
volume = {2},
number = {1-2},
pages = {83-97},
doi = {https://doi.org/10.1002/nav.3800020109},
abstract = {Abstract Assuming that numerical scores are available for the performance of each of n persons on each of n jobs, the “assignment problem” is the quest for an assignment of persons to jobs so that the sum of the n scores so obtained is as large as possible. It is shown that ideas latent in the work of two Hungarian mathematicians may be exploited to yield a new method of solving this problem.},
year = {1955}
}

@ARTICLE{RectAssign,
  author={Crouse, David F.},
  journal={IEEE Transactions on Aerospace and Electronic Systems}, 
  title={On implementing 2D rectangular assignment algorithms}, 
  year={2016},
  volume={52},
  number={4},
  pages={1679-1696},
  doi={10.1109/TAES.2016.140952}}

@inproceedings{PSR,
author = {Kazhdan, Michael and Bolitho, Matthew and Hoppe, Hugues},
title = {Poisson surface reconstruction},
year = {2006},
isbn = {3905673363},
publisher = {Eurographics Association},
address = {Goslar, DEU},
abstract = {We show that surface reconstruction from oriented points can be cast as a spatial Poisson problem. This Poisson formulation considers all the points at once, without resorting to heuristic spatial partitioning or blending, and is therefore highly resilient to data noise. Unlike radial basis function schemes, our Poisson approach allows a hierarchy of locally supported basis functions, and therefore the solution reduces to a well conditioned sparse linear system. We describe a spatially adaptive multiscale algorithm whose time and space complexities are proportional to the size of the reconstructed model. Experimenting with publicly available scan data, we demonstrate reconstruction of surfaces with greater detail than previously achievable.},
booktitle = {Proceedings of the Fourth Eurographics Symposium on Geometry Processing},
pages = {61–70},
numpages = {10},
location = {Cagliari, Sardinia, Italy},
series = {SGP '06}
}

@article{ScreenedPSR,
author = {Kazhdan, Michael and Hoppe, Hugues},
title = {Screened poisson surface reconstruction},
year = {2013},
issue_date = {June 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {3},
issn = {0730-0301},
doi = {10.1145/2487228.2487237},
abstract = {Poisson surface reconstruction creates watertight surfaces from oriented point sets. In this work we extend the technique to explicitly incorporate the points as interpolation constraints. The extension can be interpreted as a generalization of the underlying mathematical framework to a screened Poisson equation. In contrast to other image and geometry processing techniques, the screening term is defined over a sparse set of points rather than over the full domain. We show that these sparse constraints can nonetheless be integrated efficiently. Because the modified linear system retains the same finite-element discretization, the sparsity structure is unchanged, and the system can still be solved using a multigrid approach. Moreover we present several algorithmic improvements that together reduce the time complexity of the solver to linear in the number of points, thereby enabling faster, higher-quality surface reconstructions.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {29},
numpages = {13},
keywords = {Screened Poisson equation, adaptive octree, finite elements, surface fitting}
}

@article{PSREnv,
author = {Kazhdan, Misha and Chuang, Ming and Rusinkiewicz, Szymon and Hoppe, Hugues},
title = {Poisson Surface Reconstruction with Envelope Constraints},
journal = {Computer Graphics Forum},
volume = {39},
number = {5},
pages = {173-182},
keywords = {Categories and Subject Descriptors (according to ACM CCS): I.3.5 Computer Graphics: Computational Geometry and Object Modeling—Geometric algorithms, languages, and systems},
doi = {https://doi.org/10.1111/cgf.14077},
abstract = {Abstract Reconstructing surfaces from scanned 3D points has been an important research area for several decades. One common approach that has proven efficient and robust to noise is implicit surface reconstruction, i.e. fitting to the points a 3D scalar function (such as an indicator function or signed-distance field) and then extracting an isosurface. Though many techniques fall within this category, existing methods either impose no boundary constraints or impose Dirichlet/Neumann conditions on the surface of a bounding box containing the scanned data. In this work, we demonstrate the benefit of supporting Dirichlet constraints on a general boundary. To this end, we adapt the Screened Poisson Reconstruction algorithm to input a constraint envelope in addition to the oriented point cloud. We impose Dirichlet boundary conditions, forcing the reconstructed implicit function to be zero outside this constraint surface. Using a visual hull and/or depth hull derived from RGB-D scans to define the constraint envelope, we obtain substantially improved surface reconstructions in regions of missing data.},
year = {2020}
}

@inproceedings{DiffPSR,
 author = {Peng, Songyou and Jiang, Chiyu and Liao, Yiyi and Niemeyer, Michael and Pollefeys, Marc and Geiger, Andreas},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {13032--13044},
 publisher = {Curran Associates, Inc.},
 title = {Shape As Points: A Differentiable Poisson Solver},
 volume = {34},
 year = {2021}
}

@article{iPSR,
author = {Hou, Fei and Wang, Chiyu and Wang, Wencheng and Qin, Hong and Qian, Chen and He, Ying},
title = {Iterative poisson surface reconstruction (iPSR) for unoriented points},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {4},
issn = {0730-0301},
doi = {10.1145/3528223.3530096},
abstract = {Poisson surface reconstruction (PSR) remains a popular technique for reconstructing watertight surfaces from 3D point samples thanks to its efficiency, simplicity, and robustness. Yet, the existing PSR method and subsequent variants work only for oriented points. This paper intends to validate that an improved PSR, called iPSR, can completely eliminate the requirement of point normals and proceed in an iterative manner. In each iteration, iPSR takes as input point samples with normals directly computed from the surface obtained in the preceding iteration, and then generates a new surface with better quality. Extensive quantitative evaluation confirms that the new iPSR algorithm converges in 5--30 iterations even with randomly initialized normals. If initialized with a simple visibility based heuristic, iPSR can further reduce the number of iterations. We conduct comprehensive comparisons with PSR and other powerful implicit-function based methods. Finally, we confirm iPSR's effectiveness and scalability on the AIM@SHAPE dataset and challenging (indoor and outdoor) scenes. Code and data for this paper are at https://github.com/houfei0801/ipsr.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {128},
numpages = {13},
keywords = {iterative algorithm, poisson surface reconstruction, unoriented points}
}

@article{ParamGauss,
author = {Lin, Siyou and Xiao, Dong and Shi, Zuoqiang and Wang, Bin},
title = {Surface Reconstruction from Point Clouds without Normals by Parametrizing the Gauss Formula},
year = {2022},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {2},
issn = {0730-0301},
doi = {10.1145/3554730},
abstract = {We propose Parametric Gauss Reconstruction (PGR) for surface reconstruction from point clouds without normals. Our insight builds on the Gauss formula in potential theory, which represents the indicator function of a region as an integral over its boundary. By viewing surface normals and surface element areas as unknown parameters, the Gauss formula interprets the indicator as a member of some parametric function space. We can solve for the unknown parameters using the Gauss formula and simultaneously obtain the indicator function. Our method bypasses the need for accurate input normals as required by most existing non-data-driven methods, while also exhibiting superiority over data-driven methods, since no training is needed. Moreover, by modifying the Gauss formula and employing regularization, PGR also adapts to difficult cases such as noisy inputs, thin structures, sparse or nonuniform points, for which accurate normal estimation becomes quite difficult. Our code is publicly available at .},
journal = {ACM Trans. Graph.},
month = oct,
articleno = {14},
numpages = {19},
keywords = {Surface reconstruction, Gauss formula, 3D shape modeling, point-based models, mesh models}
}

@article{nPSR,
  title={Neural Poisson Surface Reconstruction: Resolution-Agnostic Shape Reconstruction from Point Clouds},
  author={Hector Andrade-Loarca and Julius Hege and Daniel Cremers and Gitta Kutyniok},
  journal={arXiv:2308.01766},
  year={2023}
}

@article{NeuralSPSR,
  title = {Neural Stochastic Screened Poisson Reconstruction},
  author = {Silvia Sellán and Alec Jacobson},
  year = {2023},
  journal = {ACM Transactions on Graphics (Proc. SIGGRAPH Asia)}
}

@inproceedings{UncPCS,
author = {Pauly, Mark and Mitra, Niloy J. and Guibas, Leonidas J.},
title = {Uncertainty and variability in point cloud surface data},
year = {2004},
isbn = {3905673096},
publisher = {Eurographics Association},
address = {Goslar, DEU},
abstract = {We present a framework for analyzing shape uncertainty and variability in point-sampled geometry. Our representation is mainly targeted towards discrete surface data stemming from 3D acquisition devices, where a finite number of possibly noisy samples provides only incomplete information about the underlying surface. We capture this uncertainty by introducing a statistical representation that quantifies for each point in space the likelihood that a surface fitting the data passes through that point. This likelihood map is constructed by aggregating local linear extrapolators computed from weighted least squares fits. The quality of fit of these extrapolators is combined into a corresponding confidence map that measures the quality of local tangent estimates. We present an analysis of the effect of noise on these maps, show how to efficiently compute them, and extend the basic definition to a scale-space formulation. Various applications of our framework are discussed, including an adaptive re-sampling method, an algorithm for reconstructing surfaces in the presence of noise, and a technique for robustly merging a set of scans into a single point-based representation.},
booktitle = {Proceedings of the First Eurographics Conference on Point-Based Graphics},
pages = {77–84},
numpages = {8},
location = {Switzerland},
series = {SPBG'04}
}

@article{SPSR,
  title = {Stochastic Poisson Surface Reconstruction},
  author = {Silvia Sellán and Alec Jacobson},
  year = {2022},
  journal = {ACM Transactions on Graphics}
}

@article{SurveyReconPC1,
author = {Berger, Matthew and Tagliasacchi, Andrea and Seversky, Lee M. and Alliez, Pierre and Guennebaud, Gaël and Levine, Joshua A. and Sharf, Andrei and Silva, Claudio T.},
title = {A Survey of Surface Reconstruction from Point Clouds},
journal = {Computer Graphics Forum},
volume = {36},
number = {1},
pages = {301-329},
keywords = {geometry processin, surface reconstruction, 3D acquisition, shape analysis},
doi = {https://doi.org/10.1111/cgf.12802},
abstract = {Abstract The area of surface reconstruction has seen substantial progress in the past two decades. The traditional problem addressed by surface reconstruction is to recover the digital representation of a physical shape that has been scanned, where the scanned data contain a wide variety of defects. While much of the earlier work has been focused on reconstructing a piece-wise smooth representation of the original shape, recent work has taken on more specialized priors to address significantly challenging data imperfections, where the reconstruction can take on different representations—not necessarily the explicit geometry. We survey the field of surface reconstruction, and provide a categorization with respect to priors, data imperfections and reconstruction output. By considering a holistic view of surface reconstruction, we show a detailed characterization of the field, highlight similarities between diverse reconstruction techniques and provide directions for future work in surface reconstruction.},
year = {2017}
}

@ARTICLE{SurveyReconPC2,
  author={Huang, ZhangJin and Wen, Yuxin and Wang, ZiHao and Ren, Jinjuan and Jia, Kui},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Surface Reconstruction From Point Clouds: A Survey and a Benchmark}, 
  year={2024},
  volume={46},
  number={12},
  pages={9727-9748},
  doi={10.1109/TPAMI.2024.3429209}}


@article{IGR,
  title={Implicit geometric regularization for learning shapes},
  author={Gropp, Amos and Yariv, Lior and Haim, Niv and Atzmon, Matan and Lipman, Yaron},
  journal={arXiv preprint arXiv:2002.10099},
  year={2020}
}

@article{SIREN,
  title={Implicit neural representations with periodic activation functions},
  author={Sitzmann, Vincent and Martel, Julien and Bergman, Alexander and Lindell, David and Wetzstein, Gordon},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={7462--7473},
  year={2020}
}

@inproceedings{IDF,
  title={Geometry-consistent neural shape representation with implicit displacement fields},
  author={Wang, Yifan and Rahmann, Lukas and Sorkine-Hornung, Olga},
  booktitle={The Tenth International Conference on Learning Representations},
  year={2022},
  organization={OpenReview}
}

@inproceedings{SAL,
  title={SAL: Sign agnostic learning of shapes from raw data},
  author={Atzmon, Matan and Lipman, Yaron},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2565--2574},
  year={2020}
}

@inproceedings{PredPrior,
  title={Surface reconstruction from point clouds by learning predictive context priors},
  author={Ma, Baorui and Liu, Yu-Shen and Zwicker, Matthias and Han, Zhizhong},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6326--6337},
  year={2022}
}

@inproceedings{SparseSurf,
  title={Reconstructing surfaces for sparse point clouds with on-surface priors},
  author={Ma, Baorui and Liu, Yu-Shen and Han, Zhizhong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6315--6325},
  year={2022}
}

@inproceedings{POCO,
  title={Poco: Point convolution for surface reconstruction},
  author={Boulch, Alexandre and Marlet, Renaud},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6302--6314},
  year={2022}
}

@inproceedings{P2Surf,
  title={Points2surf learning implicit surfaces from point clouds},
  author={Erler, Philipp and Guerrero, Paul and Ohrhallinger, Stefan and Mitra, Niloy J and Wimmer, Michael},
  booktitle={European Conference on Computer Vision},
  pages={108--124},
  year={2020},
  organization={Springer}
}

@inproceedings{DiGS,
  title={DiGS: Divergence guided shape implicit neural representation for unoriented point clouds},
  author={Ben-Shabat, Yizhak and Koneputugodage, Chamin Hewa and Gould, Stephen},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19323--19332},
  year={2022}
}

@article{SALD,
  title={SALD: Sign agnostic learning with derivatives},
  author={Atzmon, Matan and Lipman, Yaron},
  journal={arXiv preprint arXiv:2006.05400},
  year={2020}
}

@article{NeuralHessian,
author = {Wang, Zixiong and Zhang, Yunxiao and Xu, Rui and Zhang, Fan and Wang, Peng-Shuai and Chen, Shuangmin and Xin, Shiqing and Wang, Wenping and Tu, Changhe},
title = {Neural-Singular-Hessian: Implicit Neural Representation of Unoriented Point Clouds by Enforcing Singular Hessian},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {6},
issn = {0730-0301},
doi = {10.1145/3618311},
abstract = {Neural implicit representation is a promising approach for reconstructing surfaces from point clouds. Existing methods combine various regularization terms, such as the Eikonal and Laplacian energy terms, to enforce the learned neural function to possess the properties of a Signed Distance Function (SDF). However, inferring the actual topology and geometry of the underlying surface from poor-quality unoriented point clouds remains challenging. In accordance with Differential Geometry, the Hessian of the SDF is singular for points within the differential thin-shell space surrounding the surface. Our approach enforces the Hessian of the neural implicit function to have a zero determinant for points near the surface. This technique aligns the gradients for a near-surface point and its on-surface projection point, producing a rough but faithful shape within just a few iterations. By annealing the weight of the singular-Hessian term, our approach ultimately produces a high-fidelity reconstruction result. Extensive experimental results demonstrate that our approach effectively suppresses ghost geometry and recovers details from unoriented point clouds with better expressiveness than existing fitting-based methods.},
journal = {ACM Trans. Graph.},
month = dec,
articleno = {274},
numpages = {14},
}

@inproceedings{GPIS,
author = {Williams, Oliver and Fitzgibbon, Andrew},
title = {Gaussian Process Implicit Surfaces},
booktitle = {Gaussian Processes in Practice},
year = {2007},
month = {April},
abstract = {Many applications in computer vision and computer graphics require the definition of curves and surfaces. Implicit surfaces are a popular choice for this because they are smooth, can be appropriately constrained by known geometry, and require no special treatment for topology changes. In this paper we introduce Gaussian processes to this area by deriving a covariance function equivalent to the thin plate spline regularizer.},
edition = {Gaussian Processes in Practice},
}

@INPROCEEDINGS{GPISGrasp,
  author={Dragiev, Stanimir and Toussaint, Marc and Gienger, Michael},
  booktitle={2011 IEEE International Conference on Robotics and Automation}, 
  title={Gaussian process implicit surfaces for shape estimation and grasping}, 
  year={2011},
  volume={},
  number={},
  pages={2845-2850},
  doi={10.1109/ICRA.2011.5980395}
}

@INPROCEEDINGS{GPISView,
  author={Hollinger, Geoffrey A. and Englot, Brendan and Hover, Franz and Mitra, Urbashi and Sukhatme, Gaurav S.},
  booktitle={2012 IEEE International Conference on Robotics and Automation}, 
  title={Uncertainty-driven view planning for underwater inspection}, 
  year={2012},
  volume={},
  number={},
  pages={4884-4891},
  doi={10.1109/ICRA.2012.6224726}
}

@ARTICLE{GPRSeg,
  author={Shin, Myung-Ok and Oh, Gyu-Min and Kim, Seong-Woo and Seo, Seung-Woo},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Real-Time and Accurate Segmentation of 3-D Point Clouds Based on Gaussian Process Regression}, 
  year={2017},
  volume={18},
  number={12},
  pages={3363-3377},
  doi={10.1109/TITS.2017.2685523}
}

@article{GPOccMap,
author = {O'Callaghan, Simon T and Ramos, Fabio T},
title = {Gaussian process occupancy maps*},
year = {2012},
issue_date = {January   2012},
publisher = {Sage Publications, Inc.},
address = {USA},
volume = {31},
number = {1},
issn = {0278-3649},
doi = {10.1177/0278364911421039},
abstract = {We introduce a new statistical modelling technique for building occupancy maps. The problem of mapping is addressed as a classification task where the robot's environment is classified into regions of occupancy and free space. This is obtained by employing a modified Gaussian process as a non-parametric Bayesian learning technique to exploit the fact that real-world environments inherently possess structure. This structure introduces dependencies between points on the map which are not accounted for by many common mapping techniques such as occupancy grids. Our approach is an 'anytime' algorithm that is capable of generating accurate representations of large environments at arbitrary resolutions to suit many applications. It also provides inferences with associated variances into occluded regions and between sensor beams, even with relatively few observations. Crucially, the technique can handle noisy data, potentially from multiple sources, and fuse it into a robust common probabilistic representation of the robot's surroundings. We demonstrate the benefits of our approach on simulated datasets with known ground truth and in outdoor urban environments.},
journal = {Int. J. Rob. Res.},
month = jan,
pages = {42–62},
numpages = {21},
}

@INPROCEEDINGS{mixGPOccMap,
  author={Kim, Soohwan and Kim, Jonghyuk},
  booktitle={2012 IEEE International Conference on Robotics and Automation}, 
  title={Building occupancy maps with a mixture of Gaussian processes}, 
  year={2012},
  volume={},
  number={},
  pages={4756-4761},
  doi={10.1109/ICRA.2012.6225355}
}

@INPROCEEDINGS{locGPOccMap,
  author={Kim, Soohwan and Kim, Jonghyuk},
  booktitle={2013 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={Continuous occupancy maps using overlapping local Gaussian processes}, 
  year={2013},
  volume={},
  number={},
  pages={4709-4714},
  doi={10.1109/IROS.2013.6697034}}


@INPROCEEDINGS{onlineGPIS,
  author={Lee, Bhoram and Zhang, Clark and Huang, Zonghao and Lee, Daniel D.},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)}, 
  title={Online Continuous Mapping using Gaussian Process Implicit Surfaces}, 
  year={2019},
  volume={},
  number={},
  pages={6884-6890},
  doi={10.1109/ICRA.2019.8794324}
}

@article{logGPIS,
  title={Faithful Euclidean Distance Field from Log-Gaussian Process Implicit Surfaces},
  author={Wu, Lan and Lee, Ki Myung Brian and Liu, Liyang and Vidal-Calleja, Teresa},
  journal={arXiv preprint arXiv:2010.11487},
  year={2020}
}

@article{GeodesicHeat,
   title={Geodesics in heat: A new approach to computing distance based on heat flow},
   volume={32},
   ISSN={1557-7368},
   DOI={10.1145/2516971.2516977},
   number={5},
   journal={ACM Transactions on Graphics},
   publisher={Association for Computing Machinery (ACM)},
   author={Crane, Keenan and Weischedel, Clarisse and Wardetzky, Max},
   year={2013},
   month=sep, pages={1–11}
}

@ARTICLE{onlinePriorGPIS,
  author={Ivan, Jean-Paul A. and Stoyanov, Todor and Stork, Johannes A.},
  journal={IEEE Robotics and Automation Letters}, 
  title={Online Distance Field Priors for Gaussian Process Implicit Surfaces}, 
  year={2022},
  volume={7},
  number={4},
  pages={8996-9003},
  doi={10.1109/LRA.2022.3189434}
}

@ARTICLE{geoPriorGPIS,
  author={Martens, Wolfram and Poffet, Yannick and Soria, Pablo Ramón and Fitch, Robert and Sukkarieh, Salah},
  journal={IEEE Robotics and Automation Letters}, 
  title={Geometric Priors for Gaussian Process Implicit Surfaces}, 
  year={2017},
  volume={2},
  number={2},
  pages={373-380},
  doi={10.1109/LRA.2016.2631260}
}

@ARTICLE{GPDF,
  author={Le Gentil, Cedric and Ouabi, Othmane-Latif and Wu, Lan and Pradalier, Cedric and Vidal-Calleja, Teresa},
  journal={IEEE Robotics and Automation Letters}, 
  title={Accurate Gaussian-Process-Based Distance Fields With Applications to Echolocation and Mapping}, 
  year={2024},
  volume={9},
  number={2},
  pages={1365-1372},
  doi={10.1109/LRA.2023.3346759}
}

@ARTICLE{GMMGP,
  author={Zou, Qianqian and Sester, Monika},
  journal={IEEE Robotics and Automation Letters}, 
  title={3D Uncertain Implicit Surface Mapping Using GMM and GP}, 
  year={2024},
  volume={9},
  number={11},
  pages={10559-10566},
  doi={10.1109/LRA.2024.3475873}
}

@article{ptGMM,
  author       = {Amir Hertz and
                  Rana Hanocka and
                  Raja Giryes and
                  Daniel Cohen{-}Or},
  title        = {PointGMM: a Neural {GMM} Network for Point Clouds},
  journal      = {CoRR},
  year         = {2020},
  eprinttype    = {arXiv},
  eprint       = {2003.13326},
  timestamp    = {Wed, 01 Apr 2020 17:39:11 +0200},
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Background Ones %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{ReprLearn,
author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
title = {Representation Learning: A Review and New Perspectives},
year = {2013},
issue_date = {August 2013},
publisher = {IEEE Computer Society},
address = {USA},
volume = {35},
number = {8},
issn = {0162-8828},
doi = {10.1109/TPAMI.2013.50},
abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
month = aug,
pages = {1798–1828},
numpages = {31},
}

@article{DLDifficult1,
  author       = {Markus Reichstein and
                  Gustau Camps{-}Valls and
                  Bjorn Stevens and
                  Martin Jung and
                  Joachim Denzler and
                  Nuno Carvalhais and
                  Prabhat},
  title        = {Deep learning and process understanding for data-driven Earth system
                  science},
  journal      = {Nat.},
  volume       = {566},
  number       = {7743},
  pages        = {195--204},
  year         = {2019},
  doi          = {10.1038/S41586-019-0912-1},
  timestamp    = {Wed, 16 Aug 2023 13:40:18 +0200},
}

@article{DLDifficult2,
author = {Sarker, Iqbal H.},
title = {Deep Learning: A Comprehensive Overview on Techniques, Taxonomy, Applications and Research Directions},
year = {2021},
issue_date = {Nov 2021},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {2},
number = {6},
doi = {10.1007/s42979-021-00815-1},
abstract = {Deep learning (DL), a branch of machine learning (ML) and artificial intelligence (AI) is nowadays considered as a core technology of today’s Fourth Industrial Revolution (4IR or Industry 4.0). Due to its learning capabilities from data, DL technology originated from artificial neural network (ANN), has become a hot topic in the context of computing, and is widely applied in various application areas like healthcare, visual recognition, text analytics,&nbsp;cybersecurity, and many more. However, building an appropriate DL model is a challenging task, due to the dynamic nature and variations in real-world problems and data. Moreover, the lack of core understanding turns DL methods into black-box machines that hamper development at the standard level. This article presents a structured and comprehensive view on DL techniques including a taxonomy considering various types of real-world tasks like supervised or unsupervised. In our taxonomy, we take into account deep networks for supervised or discriminative learning, unsupervised or generative learning as well as hybrid learning and relevant others. We also summarize real-world application areas where deep learning techniques can be used. Finally, we point out ten potential aspects for future generation DL modeling with research directions. Overall, this article aims to draw a big picture on DL modeling that can be used as a reference guide for both academia and industry professionals.},
journal = {SN Comput. Sci.},
month = aug,
numpages = {20},
}

@article{DLDisaster1,
  title={Image4Act: Online Social Media Image Processing for Disaster Response},
  author={Firoj Alam and Muhammad Imran and Ferda Ofli},
  journal={2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)},
  year={2017},
  pages={601-604},
}

@article{DLDisaster2,
  author       = {Edmon Begoli and
                  Tanmoy Bhattacharya and
                  Dimitri Kusnezov},
  title        = {The need for uncertainty quantification in machine-assisted medical
                  decision making},
  journal      = {Nat. Mach. Intell.},
  volume       = {1},
  number       = {1},
  pages        = {20--23},
  year         = {2019},
  doi          = {10.1038/S42256-018-0004-1},
  timestamp    = {Sun, 19 Jan 2025 14:59:47 +0100},
}

@article{DLDisaster3,
author = {Tian, Daxin and Lin, Chunmian and Zhou, Jianshan and Duan, Xuting and Cao, Yue and Zhao, Dezong and Cao, Dongpu},
title = {SA-YOLOv3: An Efficient and Accurate Object Detector Using Self-Attention Mechanism for Autonomous Driving},
year = {2022},
issue_date = {May 2022},
publisher = {IEEE Press},
volume = {23},
number = {5},
issn = {1524-9050},
doi = {10.1109/TITS.2020.3041278},
abstract = {Object detection is becoming increasingly significant for autonomous-driving system. However, poor accuracy or low inference performance limits current object detectors in applying to autonomous driving. In this work, a fast and accurate object detector termed as SA-YOLOv3, is proposed by introducing dilated convolution and self-attention module (SAM) into the architecture of YOLOv3. Furthermore, loss function based on GIoU and focal loss is reconstructed to further optimize detection performance. With an input size of <inline-formula> <tex-math notation="LaTeX">$512times 512$ </tex-math></inline-formula>, our proposed SA-YOLOv3 improves YOLOv3 by 2.58 mAP and 2.63 mAP on KITTI and BDD100K benchmarks, with real-time inference (more than 40 FPS). When compared with other state-of-the-art detectors, it reports better trade-off in terms of detection accuracy and speed, indicating the suitability for autonomous-driving application. To our best knowledge, it is the first method that incorporates YOLOv3 with attention mechanism, and we expect this work would guide for autonomous-driving research in the future.},
journal = {Trans. Intell. Transport. Sys.},
month = may,
pages = {4099–4110},
numpages = {12}
}

@inproceedings{DLDisaster4,
author = {Balayn, Agathe and Rikalo, Natasa and Yang, Jie and Bozzon, Alessandro},
title = {Faulty or Ready? Handling Failures in Deep-Learning Computer Vision Models until Deployment: A Study of Practices, Challenges, and Needs},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/3544548.3581555},
abstract = {Handling failures in computer vision systems that rely on deep learning models remains a challenge. While an increasing number of methods for bug identification and correction are proposed, little is known about how practitioners actually search for failures in these models. We perform an empirical study to understand the goals and needs of practitioners, the workflows and artifacts they use, and the challenges and limitations in their process. We interview 18 practitioners by probing them with a carefully crafted failure handling scenario. We observe that there is a great diversity of failure handling workflows in which cooperations are often necessary, that practitioners overlook certain types of failures and bugs, and that they generally do not rely on potentially relevant approaches and tools originally stemming from research. These insights allow to draw a list of research opportunities, such as creating a library of best practices and more representative formalisations of practitioners’ goals, developing interfaces to exploit failure handling artifacts, as well as providing specialized training.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {11},
numpages = {20},
location = {Hamburg, Germany},
series = {CHI '23}
}

@article{UncertDeepL,
  author       = {Alex Kendall and
                  Yarin Gal},
  title        = {What Uncertainties Do We Need in Bayesian Deep Learning for Computer
                  Vision?},
  journal      = {CoRR},
  volume       = {abs/1703.04977},
  year         = {2017},
  eprinttype    = {arXiv},
  eprint       = {1703.04977},
  timestamp    = {Mon, 13 Aug 2018 16:48:58 +0200},
}

@inproceedings{UncertDeepLv2,
author = {Kendall, Alex and Gal, Yarin},
title = {What uncertainties do we need in Bayesian deep learning for computer vision?},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {There are two major types of uncertainty one can model. Aleatoric uncertainty captures noise inherent in the observations. On the other hand, epistemic uncertainty accounts for uncertainty in the model - uncertainty which can be explained away given enough data. Traditionally it has been difficult to model epistemic uncertainty in computer vision, but with new Bayesian deep learning tools this is now possible. We study the benefits of modeling epistemic vs. aleatoric uncertainty in Bayesian deep learning models for vision tasks. For this we present a Bayesian deep learning framework combining input-dependent aleatoric uncertainty together with epistemic uncertainty. We study models under the framework with per-pixel semantic segmentation and depth regression tasks. Further, our explicit uncertainty formulation leads to new loss functions for these tasks, which can be interpreted as learned attenuation. This makes the loss more robust to noisy data, also giving new state-of-the-art results on segmentation and depth regression benchmarks.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {5580–5590},
numpages = {11},
location = {Long Beach, California, USA},
series = {NIPS'17}
}

@phdthesis{UncertDeepL2,
  title={Uncertainty in Deep Learning},
  author={Yarin Gal},
  school={University of Cambridge},
  year={2016},
}

@article{UncertDeepNNSurvey,
author = {Gawlikowski, Jakob and Tassi, Cedrique Rovile Njieutcheu and Ali, Mohsin and Lee, Jongseok and Humt, Matthias and Feng, Jianxiang and Kruspe, Anna and Triebel, Rudolph and Jung, Peter and Roscher, Ribana and Shahzad, Muhammad and Yang, Wen and Bamler, Richard and Zhu, Xiao Xiang},
title = {A survey of uncertainty in deep neural networks},
year = {2023},
issue_date = {Oct 2023},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {56},
number = {Suppl 1},
issn = {0269-2821},
doi = {10.1007/s10462-023-10562-9},
abstract = {Over the last decade, neural networks have reached almost every field of science and become a crucial part of various real world applications. Due to the increasing spread, confidence in neural network predictions has become more and more important. However, basic neural networks do not deliver certainty estimates or suffer from over- or under-confidence, i.e. are badly calibrated. To overcome this, many researchers have been working on understanding and quantifying uncertainty in a neural network’s prediction. As a result, different types and sources of uncertainty have been identified and various approaches to measure and quantify uncertainty in neural networks have been proposed. This work gives a comprehensive overview of uncertainty estimation in neural networks, reviews recent advances in the field, highlights current challenges, and identifies potential research opportunities. It is intended to give anyone interested in uncertainty estimation in neural networks a broad overview and introduction, without presupposing prior knowledge in this field. For that, a comprehensive introduction to the most crucial sources of uncertainty is given and their separation into reducible model uncertainty and irreducible data uncertainty is presented. The modeling of these uncertainties based on deterministic neural networks, Bayesian neural networks (BNNs), ensemble of neural networks, and test-time data augmentation approaches is introduced and different branches of these fields as well as the latest developments are discussed. For a practical application, we discuss different measures of uncertainty, approaches for calibrating neural networks, and give an overview of existing baselines and available implementations. Different examples from the wide spectrum of challenges in the fields of medical image analysis, robotics, and earth observation give an idea of the needs and challenges regarding uncertainties in the practical applications of neural networks. Additionally, the practical limitations of uncertainty quantification methods in neural networks for mission- and safety-critical real world applications are discussed and an outlook on the next steps towards a broader usage of such methods is given.},
journal = {Artif. Intell. Rev.},
month = jul,
pages = {1513–1589},
numpages = {77}
}

@book{BayesNN,
author = {Neal, Radford M.},
title = {Bayesian Learning for Neural Networks},
year = {1996},
isbn = {0387947248},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {From the Publisher:Artificial "neural networks" are now widely used as flexible models for regression classification applications, but questions remain regarding what these models mean, and how they can safely be used when training data is limited. Bayesian Learning for Neural Networks shows that Bayesian methods allow complex neural network models to be used without fear of the "overfitting" that can occur with traditional neural network learning methods. Insight into the nature of these complex Bayesian models is provided by a theoretical investigation of the priors over functions that underlie them. Use of these models in practice is made possible using Markov chain Monte Carlo techniques. Both the theoretical and computational aspects of this work are of wider statistical interest, as they contribute to a better understanding of how Bayesian methods can be applied to complex problems. Presupposing only the basic knowledge of probability and statistics, this book should be of interest to many researchers in statistics, engineering, and artificial intelligence. Software for Unix systems that implements the methods described is freely available over the Internet.}
}

@article{VIReview,
  author       = {David M. Blei and
                  Alp Kucukelbir and
                  Jon D. McAuliffe},
  title        = {Variational Inference: {A} Review for Statisticians},
  journal      = {CoRR},
  volume       = {abs/1601.00670},
  year         = {2016},
  eprinttype    = {arXiv},
  eprint       = {1601.00670},
  timestamp    = {Mon, 13 Aug 2018 16:48:18 +0200},
}

@inproceedings{VIPractical,
author = {Graves, Alex},
title = {Practical variational inference for neural networks},
year = {2011},
isbn = {9781618395993},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Variational methods have been previously explored as a tractable approximation to Bayesian inference for neural networks. However the approaches proposed so far have only been applicable to a few simple network architectures. This paper introduces an easy-to-implement stochastic variational method (or equivalently, minimum description length loss function) that can be applied to most neural networks. Along the way it revisits several common regularisers from a variational perspective. It also provides a simple pruning heuristic that can both drastically reduce the number of network weights and lead to improved generalisation. Experimental results are provided for a hierarchical multidimensional recurrent neural network applied to the TIMIT speech corpus.},
booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems},
pages = {2348–2356},
numpages = {9},
location = {Granada, Spain},
series = {NIPS'11}
}

@article{LaplaceApprox,
title = {Variational free energy and the Laplace approximation},
journal = {NeuroImage},
volume = {34},
number = {1},
pages = {220-234},
year = {2007},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2006.08.035},
author = {Karl Friston and Jérémie Mattout and Nelson Trujillo-Barreto and John Ashburner and Will Penny},
abstract = {This note derives the variational free energy under the Laplace approximation, with a focus on accounting for additional model complexity induced by increasing the number of model parameters. This is relevant when using the free energy as an approximation to the log-evidence in Bayesian model averaging and selection. By setting restricted maximum likelihood (ReML) in the larger context of variational learning and expectation maximisation (EM), we show how the ReML objective function can be adjusted to provide an approximation to the log-evidence for a particular model. This means ReML can be used for model selection, specifically to select or compare models with different covariance components. This is useful in the context of hierarchical models because it enables a principled selection of priors that, under simple hyperpriors, can be used for automatic model selection and relevance determination (ARD). Deriving the ReML objective function, from basic variational principles, discloses the simple relationships among Variational Bayes, EM and ReML. Furthermore, we show that EM is formally identical to a full variational treatment when the precisions are linear in the hyperparameters. Finally, we also consider, briefly, dynamic models and how these inform the regularisation of free energy ascent schemes, like EM and ReML.}
}

@article{VIUncNN,
  title={Variational Inference to Measure Model Uncertainty in Deep Neural Networks},
  author={Konstantin Posch and Jan Steinbrener and J{\"u}rgen Pilz},
  journal={ArXiv},
  year={2019},
  volume={abs/1902.10189},
}

@article{CorrUncDNN,
author = {Posch, Konstantin and Pilz, Jürgen},
year = {2020},
month = {04},
pages = {1-15},
title = {Correlated Parameters to Accurately Measure Uncertainty in Deep Neural Networks},
volume = {PP},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
doi = {10.1109/TNNLS.2020.2980004}
}

@article{SVI,
author = {Hoffman, Matthew D. and Blei, David M. and Wang, Chong and Paisley, John},
title = {Stochastic variational inference},
year = {2013},
issue_date = {January 2013},
publisher = {JMLR.org},
volume = {14},
number = {1},
issn = {1532-4435},
abstract = {We develop stochastic variational inference, a scalable algorithm for approximating posterior distributions. We develop this technique for a large class of probabilistic models and we demonstrate it with two probabilistic topic models, latent Dirichlet allocation and the hierarchical Dirichlet process topic model. Using stochastic variational inference, we analyze several large collections of documents: 300K articles from Nature, 1.8M articles from The New York Times, and 3.8M articles from Wikipedia. Stochastic inference can easily handle data sets of this size and outperforms traditional variational inference, which can only handle a smaller subset. (We also show that the Bayesian nonparametric topic model outperforms its parametric counterpart.) Stochastic variational inference lets us apply complex Bayesian models to massive data sets.},
journal = {J. Mach. Learn. Res.},
month = May,
pages = {1303–1347},
numpages = {45}
}

@inproceedings{MCVIBridge,
author = {Salimans, Tim and Kingma, Diederik P. and Welling, Max},
title = {Markov Chain Monte Carlo and variational inference: bridging the gap},
year = {2015},
publisher = {JMLR.org},
abstract = {Recent advances in stochastic gradient variational inference have made it possible to perform variational Bayesian inference with posterior approximations containing auxiliary random variables. This enables us to explore a new synthesis of variational inference and Monte Carlo methods where we incorporate one or more steps of MCMC into our variational approximation. By doing so we obtain a rich class of inference algorithms bridging the gap between variational methods and MCMC, and offering the best of both worlds: fast posterior approximation through the maximization of an explicit objective, with the option of trading off additional computation for additional accuracy. We describe the theoretical foundations that make this possible and show some promising first results.},
booktitle = {Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37},
pages = {1218–1226},
numpages = {9},
location = {Lille, France},
series = {ICML'15}
}

@book{ProbMLBook,
author = {Murphy, Kevin P.},
title = {Machine Learning: A Probabilistic Perspective},
year = {2012},
isbn = {0262018020},
publisher = {The MIT Press},
abstract = {Today's Web-enabled deluge of electronic data calls for automated methods of data analysis. Machine learning provides these, developing methods that can automatically detect patterns in data and then use the uncovered patterns to predict future data. This textbook offers a comprehensive and self-contained introduction to the field of machine learning, based on a unified, probabilistic approach. The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a MATLAB software package--PMTK (probabilistic modeling toolkit)--that is freely available online. The book is suitable for upper-level undergraduates with an introductory-level college math background and beginning graduate students.}
}

@article{DropoutUQ,
author = {Gal, Yarin and Ghahramani, Zoubin},
year = {2015},
month = {06},
pages = {},
title = {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
journal = {Proceedings of The 33rd International Conference on Machine Learning}
}

@article{DropoutOG,
author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
title = {Dropout: a simple way to prevent neural networks from overfitting},
year = {2014},
issue_date = {January 2014},
publisher = {JMLR.org},
volume = {15},
number = {1},
issn = {1532-4435},
abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different "thinned" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {1929–1958},
numpages = {30},
keywords = {deep learning, model combination, neural networks, regularization}
}

@inproceedings{DropoutIssues1,
author = {Nguyen, Son and Nguyen, Duong and Nguyen, Khai and Than, Khoat and Bui, Hung and Ho, Nhat},
title = {Structured dropout variational inference for Bayesian neural networks},
year = {2021},
isbn = {9781713845393},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Approximate inference in Bayesian deep networks exhibits a dilemma of how to yield high fidelity posterior approximations while maintaining computational efficiency and scalability. We tackle this challenge by introducing a novel variational structured approximation inspired by the Bayesian interpretation of Dropout regularization. Concretely, we focus on the inflexibility of the factorized structure in Dropout posterior and then propose an improved method called Variational Structured Dropout (VSD). VSD employs an orthogonal transformation to learn a structured representation on the variational Gaussian noise with plausible complexity, and consequently induces statistical dependencies in the approximate posterior. Theoretically, VSD successfully addresses the pathologies of previous Variational Dropout methods and thus offers a standard Bayesian justification. We further show that VSD induces an adaptive regularization term with several desirable properties which contribute to better generalization. Finally, we conduct extensive experiments on standard benchmarks to demonstrate the effectiveness of VSD over state-of-the-art variational methods on predictive accuracy, uncertainty estimation, and out-of-distribution detection.},
booktitle = {Proceedings of the 35th International Conference on Neural Information Processing Systems},
articleno = {1164},
numpages = {15},
series = {NIPS '21}
}

@inproceedings{DropoutIssues2,
 author = {Foong, Andrew and Burt, David and Li, Yingzhen and Turner, Richard},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {15897--15908},
 publisher = {Curran Associates, Inc.},
 title = {On the Expressiveness of Approximate Inference in Bayesian Neural Networks},
 volume = {33},
 year = {2020}
}

@article{BayesCNN,
Author = {Yarin Gal and Zoubin Ghahramani},
Title = {Bayesian Convolutional Neural Networks with {B}ernoulli Approximate Variational Inference},
Year = {2015},
Journal = {arXiv:1506.02158},
}

@article{BayesSegNetUnc,
  author       = {Alex Kendall and
                  Vijay Badrinarayanan and
                  Roberto Cipolla},
  title        = {Bayesian SegNet: Model Uncertainty in Deep Convolutional Encoder-Decoder
                  Architectures for Scene Understanding},
  journal      = {CoRR},
  volume       = {abs/1511.02680},
  year         = {2015},
  eprinttype    = {arXiv},
  eprint       = {1511.02680},
  timestamp    = {Mon, 13 Aug 2018 16:46:05 +0200}
}

@article{DropConnectUQ,
  author       = {Aryan Mobiny and
                  Hien Van Nguyen and
                  Supratik Moulik and
                  Naveen Garg and
                  Carol C. Wu},
  title        = {DropConnect Is Effective in Modeling Uncertainty of Bayesian Deep
                  Networks},
  journal      = {CoRR},
  volume       = {abs/1906.04569},
  year         = {2019},
  eprinttype    = {arXiv},
  eprint       = {1906.04569},
  timestamp    = {Fri, 14 Jun 2019 09:38:24 +0200}
}


@InProceedings{DropConnectOG,
  title = 	 {Regularization of Neural Networks using DropConnect},
  author = 	 {Wan, Li and Zeiler, Matthew and Zhang, Sixin and Le Cun, Yann and Fergus, Rob},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
  pages = 	 {1058--1066},
  year = 	 {2013},
  editor = 	 {Dasgupta, Sanjoy and McAllester, David},
  volume = 	 {28},
  number =       {3},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Atlanta, Georgia, USA},
  month = 	 {17--19 Jun},
  publisher =    {PMLR},
  abstract = 	 {We introduce DropConnect, a generalization of DropOut, for regularizing large fully-connected layers within neural networks. When training with Dropout, a randomly selected subset of activations are set to zero within each layer. DropConnect instead sets a randomly selected subset of weights within the network to zero. Each unit thus receives input from a random subset of units in the previous layer. We derive a bound on the generalization performance of both Dropout and DropConnect. We then evaluate DropConnect on a range of datasets, comparing to Dropout, and show state-of-the-art results on several image recoginition benchmarks can be obtained by aggregating multiple DropConnect-trained models.}
}

@InProceedings{EnsembleReview,
author="Dietterich, Thomas G.",
title="Ensemble Methods in Machine Learning",
booktitle="Multiple Classifier Systems",
year="2000",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--15",
abstract="Ensemble methods are learning algorithms that construct a set of classifiers and then classify new data points by taking a (weighted) vote of their predictions. The original ensemble method is Bayesian averaging, but more recent algorithms include error-correcting output coding, Bagging, and boosting. This paper reviews these methods and explains why ensembles can often perform better than any single classifier. Some previous studies comparing ensemble methods are reviewed, and some new experiments are presented to uncover the reasons that Adaboost does not overfit rapidly.",
isbn="978-3-540-45014-6"
}

@ARTICLE{EnsembleNN,
  author={Hansen, L.K. and Salamon, P.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Neural network ensembles}, 
  year={1990},
  volume={12},
  number={10},
  pages={993-1001},
  keywords={Neural networks;Databases;Fault tolerance;Supervised learning;Pattern recognition;Computer architecture;Neurons;Data mining;Feedforward systems;Performance analysis},
  doi={10.1109/34.58871}
}

@inproceedings{EnsembleNN2,
 author = {Krogh, Anders and Vedelsby, Jesper},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {G. Tesauro and D. Touretzky and T. Leen},
 pages = {},
 publisher = {MIT Press},
 title = {Neural Network Ensembles, Cross Validation, and Active Learning},
 volume = {7},
 year = {1994}
}

@article{EnsembleNN3,
title = {Ensembling neural networks: Many could be better than all},
journal = {Artificial Intelligence},
volume = {137},
number = {1},
pages = {239-263},
year = {2002},
issn = {0004-3702},
doi = {https://doi.org/10.1016/S0004-3702(02)00190-X},
author = {Zhi-Hua Zhou and Jianxin Wu and Wei Tang},
abstract = {Neural network ensemble is a learning paradigm where many neural networks are jointly used to solve a problem. In this paper, the relationship between the ensemble and its component neural networks is analyzed from the context of both regression and classification, which reveals that it may be better to ensemble many instead of all of the neural networks at hand. This result is interesting because at present, most approaches ensemble all the available neural networks for prediction. Then, in order to show that the appropriate neural networks for composing an ensemble can be effectively selected from a set of available neural networks, an approach named GASEN is presented. GASEN trains a number of neural networks at first. Then it assigns random weights to those networks and employs genetic algorithm to evolve the weights so that they can characterize to some extent the fitness of the neural networks in constituting an ensemble. Finally it selects some neural networks based on the evolved weights to make up the ensemble. A large empirical study shows that, compared with some popular ensemble approaches such as Bagging and Boosting, GASEN can generate neural network ensembles with far smaller sizes but stronger generalization ability. Furthermore, in order to understand the working mechanism of GASEN, the bias-variance decomposition of the error is provided in this paper, which shows that the success of GASEN may lie in that it can significantly reduce the bias as well as the variance.}
}

@inproceedings{DeepEnsembleUQ,
author = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
title = {Simple and scalable predictive uncertainty estimation using deep ensembles},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Deep neural networks (NNs) are powerful black box predictors that have recently achieved impressive performance on a wide spectrum of tasks. Quantifying predictive uncertainty in NNs is a challenging and yet unsolved problem. Bayesian NNs, which learn a distribution over weights, are currently the state-of-the-art for estimating predictive uncertainty; however these require significant modifications to the training procedure and are computationally expensive compared to standard (non-Bayesian) NNs. We propose an alternative to Bayesian NNs that is simple to implement, readily parallelizable, requires very little hyperparameter tuning, and yields high quality predictive uncertainty estimates. Through a series of experiments on classification and regression benchmarks, we demonstrate that our method produces well-calibrated uncertainty estimates which are as good or better than approximate Bayesian NNs. To assess robustness to dataset shift, we evaluate the predictive uncertainty on test examples from known and unknown distributions, and show that our method is able to express higher uncertainty on out-of-distribution examples. We demonstrate the scalability of our method by evaluating predictive uncertainty estimates on ImageNet.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {6405–6416},
numpages = {12},
location = {Long Beach, California, USA},
series = {NIPS'17}
}

@inproceedings{Adversarial,
  author       = {Ian J. Goodfellow and
                  Jonathon Shlens and
                  Christian Szegedy},
  editor       = {Yoshua Bengio and
                  Yann LeCun},
  title        = {Explaining and Harnessing Adversarial Examples},
  booktitle    = {3rd International Conference on Learning Representations, {ICLR} 2015,
                  San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year         = {2015},
  timestamp    = {Thu, 25 Jul 2019 14:25:38 +0200}
}

@inproceedings{NeuBoots,
 author = {Shin, Minsuk and Cho, Hyungjoo and Min, Hyun-seok and Lim, Sungbin},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
 pages = {16596--16609},
 publisher = {Curran Associates, Inc.},
 title = {Neural Bootstrapper},
 volume = {34},
 year = {2021}
}

@inproceedings{HyperparEnsUnc,
author = {Wenzel, Florian and Snoek, Jasper and Tran, Dustin and Jenatton, Rodolphe},
title = {Hyperparameter ensembles for robustness and uncertainty quantification},
year = {2020},
isbn = {9781713829546},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Ensembles over neural network weights trained from different random initialization, known as deep ensembles, achieve state-of-the-art accuracy and calibration. The recently introduced batch ensembles provide a drop-in replacement that is more parameter efficient. In this paper, we design ensembles not only over weights, but over hyperparameters to improve the state of the art in both settings. For best performance independent of budget, we propose hyper-deep ensembles, a simple procedure that involves a random search over different hyperparameters, themselves stratified across multiple random initializations. Its strong performance highlights the benefit of combining models with both weight and hyperparameter diversity. We further propose a parameter efficient version, hyper-batch ensembles, which builds on the layer structure of batch ensembles and self-tuning networks. The computational and memory costs of our method are notably lower than typical ensembles. On image classification tasks, with MLP, LeNet, ResNet 20 and Wide ResNet 28-10 architectures, we improve upon both deep and batch ensembles.},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
articleno = {546},
numpages = {14},
location = {Vancouver, BC, Canada},
series = {NIPS '20}
}

@article{BatchEnsemble,
  author       = {Yeming Wen and
                  Dustin Tran and
                  Jimmy Ba},
  title        = {BatchEnsemble: An Alternative Approach to Efficient Ensemble and Lifelong
                  Learning},
  journal      = {CoRR},
  volume       = {abs/2002.06715},
  year         = {2020},
  eprinttype    = {arXiv},
  eprint       = {2002.06715},
  timestamp    = {Mon, 02 Mar 2020 16:46:06 +0100},
}

@article{Masksembles,
  author       = {Nikita Durasov and
                  Timur M. Bagautdinov and
                  Pierre Baqu{\'{e}} and
                  Pascal Fua},
  title        = {Masksembles for Uncertainty Estimation},
  journal      = {CoRR},
  volume       = {abs/2012.08334},
  year         = {2020},
  eprinttype    = {arXiv},
  eprint       = {2012.08334},
  timestamp    = {Sun, 03 Jan 2021 16:00:24 +0100},
}

@inproceedings{AlexNet,
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
title = {ImageNet classification with deep convolutional neural networks},
year = {2012},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overriding in the fully-connected layers we employed a recently-developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
booktitle = {Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 1},
pages = {1097–1105},
numpages = {9},
location = {Lake Tahoe, Nevada},
series = {NIPS'12}
}

@inproceedings{PackedEnsemble,
title={Packed Ensembles for efficient uncertainty estimation},
author={Olivier Laurent and Adrien Lafage and Enzo Tartaglione and Geoffrey Daniel and Jean-marc Martinez and Andrei Bursuc and Gianni Franchi},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
}

@inproceedings{DeepEnsVarBayes,
author = {Wild, Veit D. and Ghalebikesabi, Sahra and Sejdinovic, Dino and Knoblauch, Jeremias},
title = {A rigorous link between deep ensembles and (variational) Bayesian methods},
year = {2023},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We establish the first mathematically rigorous link between Bayesian, variational Bayesian, and ensemble methods. A key step towards this is to reformulate the non-convex optimisation problem typically encountered in deep learning as a convex optimisation in the space of probability measures. On a technical level, our contribution amounts to studying generalised variational inference through the lens of Wasserstein gradient flows. The result is a unified theory of various seemingly disconnected approaches that are commonly used for uncertainty quantification in deep learning—including deep ensembles and (variational) Bayesian methods. This offers a fresh perspective on the reasons behind the success of deep ensembles over procedures based on standard variational inference, and allows the derivation of new ensembling schemes with convergence guarantees. We showcase this by proposing a family of interacting deep ensembles with direct parallels to the interactions of particle systems in thermodynamics, and use our theory to prove the convergence of these algorithms to a well-defined global minimiser on the space of probability measures.},
booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
articleno = {1729},
numpages = {30},
location = {New Orleans, LA, USA},
series = {NIPS '23}
}


@article{LearnIGM,
  title={Learning in Implicit Generative Models},
  author={Shakir Mohamed and Balaji Lakshminarayanan},
  journal={ArXiv},
  year={2016},
  volume={abs/1610.03483},
}


@book{GPML,
author = {Rasmussen, Carl Edward and Williams, Christopher K. I.},
title = {Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)},
year = {2005},
isbn = {026218253X},
publisher = {The MIT Press}
}


@InProceedings{DKL,
  title = 	 {Deep Kernel Learning},
  author = 	 {Wilson, Andrew Gordon and Hu, Zhiting and Salakhutdinov, Ruslan and Xing, Eric P.},
  booktitle = 	 {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {370--378},
  year = 	 {2016},
  editor = 	 {Gretton, Arthur and Robert, Christian C.},
  volume = 	 {51},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Cadiz, Spain},
  month = 	 {09--11 May},
  publisher =    {PMLR},
  abstract = 	 {We introduce scalable deep kernels, which combine the structural properties of deep learning architectures with the non-parametric flexibility of kernel methods.  Specifically, we transform the inputs of a spectral mixture base kernel with a deep architecture, using local kernel interpolation, inducing points, and structure exploiting (Kronecker and Toeplitz) algebra for a scalable kernel representation.  These closed-form kernels can be used as drop-in replacements for standard kernels, with benefits in expressive power and scalability.  We jointly learn the properties of these kernels through the marginal likelihood of a Gaussian process.  Inference and learning cost O(n) for n training points, and predictions cost O(1) per test point.  On a large and diverse collection of applications, including a dataset with 2 million examples, we show improved performance over scalable Gaussian processes with flexible kernel learning models, and stand-alone deep architectures.}
}

@inproceedings{SVDKL,
author = {Wilson, Andrew Gordon and Hu, Zhiting and Salakhutdinov, Ruslan and Xing, Eric P.},
title = {Stochastic variational deep kernel learning},
year = {2016},
isbn = {9781510838819},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Deep kernel learning combines the non-parametric flexibility of kernel methods with the inductive biases of deep learning architectures. We propose a novel deep kernel learning model and stochastic variational inference procedure which generalizes deep kernel learning approaches to enable classification, multi-task learning, additive covariance structures, and stochastic gradient training. Specifically, we apply additive base kernels to subsets of output features from deep neural architectures, and jointly learn the parameters of the base kernels and deep network through a Gaussian process marginal likelihood objective. Within this framework, we derive an efficient form of stochastic variational inference which leverages local kernel interpolation, inducing points, and structure exploiting algebra. We show improved performance over stand alone deep networks, SVMs, and state of the art scalable Gaussian processes on several classification benchmarks, including an airline delay dataset containing 6 million training points, CIFAR, and ImageNet.},
booktitle = {Proceedings of the 30th International Conference on Neural Information Processing Systems},
pages = {2594–2602},
numpages = {9},
location = {Barcelona, Spain},
series = {NIPS'16}
}


@InProceedings{DeepGP,
  title = 	 {Deep {G}aussian Processes},
  author = 	 {Damianou, Andreas and Lawrence, Neil D.},
  booktitle = 	 {Proceedings of the Sixteenth International Conference on Artificial Intelligence and Statistics},
  pages = 	 {207--215},
  year = 	 {2013},
  editor = 	 {Carvalho, Carlos M. and Ravikumar, Pradeep},
  volume = 	 {31},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Scottsdale, Arizona, USA},
  month = 	 {29 Apr--01 May},
  publisher =    {PMLR},
  abstract = 	 {In this paper we introduce deep Gaussian process (GP) models. Deep GPs are a deep belief network based on Gaussian process mappings. The data is modeled as the output of a multivariate GP. The inputs to that Gaussian process are then governed by another GP. A single layer model is equivalent to a standard GP or the GP latent variable model (GP-LVM). We perform inference in the model by approximate variational marginalization. This results in a strict lower bound on the marginal likelihood of the model which we use for model selection (number of layers and nodes per layer). Deep belief networks are typically applied to relatively large data sets using stochastic gradient descent for optimization. Our fully Bayesian treatment allows for the application of deep models even when data is scarce. Model selection by our variational bound shows that a five layer hierarchy is justified even when modelling a digit data set containing only 150 examples.}
}

@INPROCEEDINGS{ContLoss,
  author={Chopra, S. and Hadsell, R. and LeCun, Y.},
  booktitle={2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)}, 
  title={Learning a similarity metric discriminatively, with application to face verification}, 
  year={2005},
  volume={1},
  number={},
  pages={539-546 vol. 1},
  keywords={Character generation;Drives;Robustness;System testing;Spatial databases;Glass;Artificial neural networks;Support vector machines;Support vector machine classification;Face recognition},
  doi={10.1109/CVPR.2005.202}
}

@inproceedings{PairMarginCL,
author = {Hadsell, Raia and Chopra, Sumit and LeCun, Yann},
title = {Dimensionality Reduction by Learning an Invariant Mapping},
year = {2006},
isbn = {0769525970},
publisher = {IEEE Computer Society},
address = {USA},
doi = {10.1109/CVPR.2006.100},
abstract = {Dimensionality reduction involves mapping a set of high dimensional input points onto a low dimensional manifold so that 'similar" points in input space are mapped to nearby points on the manifold. We present a method - called Dimensionality Reduction by Learning an Invariant Mapping (DrLIM) - for learning a globally coherent nonlinear function that maps the data evenly to the output manifold. The learning relies solely on neighborhood relationships and does not require any distancemeasure in the input space. The method can learn mappings that are invariant to certain transformations of the inputs, as is demonstrated with a number of experiments. Comparisons are made to other techniques, in particular LLE.},
booktitle = {Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Volume 2},
pages = {1735–1742},
numpages = {8},
series = {CVPR '06}
}

@inproceedings{SpaceMesh,
author = {Shen, Tianchang and Li, Zhaoshuo and Law, Marc and Atzmon, Matan and Fidler, Sanja and Lucas, James and Gao, Jun and Sharp, Nicholas},
title = {SpaceMesh: A Continuous Representation for Learning Manifold Surface Meshes},
year = {2024},
isbn = {9798400711312},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/3680528.3687634},
abstract = {Meshes are ubiquitous in visual computing and simulation, yet most existing machine learning techniques represent meshes only indirectly, e.g. as the level set of a scalar field or deformation of a template, or as a disordered triangle soup lacking local structure. This work presents a scheme to directly generate manifold, polygonal meshes of complex connectivity as the output of a neural network. Our key innovation is to define a continuous latent connectivity space at each mesh vertex, which implies the discrete mesh. In particular, our vertex embeddings generate cyclic neighbor relationships in a halfedge mesh representation, which gives a guarantee of edge-manifoldness and the ability to represent general polygonal meshes. This representation is well-suited to machine learning and stochastic optimization, without restriction on connectivity or topology. We first explore the basic properties of this representation, then use it to fit distributions of meshes from large datasets. The resulting models generate diverse meshes with tessellation structure learned from the dataset population, with concise details and high-quality mesh elements. In applications, this approach not only yields high-quality outputs from generative models, but also enables directly learning challenging geometry processing tasks such as mesh repair.},
booktitle = {SIGGRAPH Asia 2024 Conference Papers},
articleno = {78},
numpages = {11},
location = {Tokyo, Japan},
series = {SA '24}
}

@inproceedings{SupervisedCont,
 author = {Khosla, Prannay and Teterwak, Piotr and Wang, Chen and Sarna, Aaron and Tian, Yonglong and Isola, Phillip and Maschinot, Aaron and Liu, Ce and Krishnan, Dilip},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {18661--18673},
 publisher = {Curran Associates, Inc.},
 title = {Supervised Contrastive Learning},
 volume = {33},
 year = {2020}
}

@Article{SelfSupervisedCont,
AUTHOR = {Jaiswal, Ashish and Babu, Ashwin Ramesh and Zadeh, Mohammad Zaki and Banerjee, Debapriya and Makedon, Fillia},
TITLE = {A Survey on Contrastive Self-Supervised Learning},
JOURNAL = {Technologies},
VOLUME = {9},
YEAR = {2021},
NUMBER = {1},
ARTICLE-NUMBER = {2},
ISSN = {2227-7080},
ABSTRACT = {Self-supervised learning has gained popularity because of its ability to avoid the cost of annotating large-scale datasets. It is capable of adopting self-defined pseudolabels as supervision and use the learned representations for several downstream tasks. Specifically, contrastive learning has recently become a dominant component in self-supervised learning for computer vision, natural language processing (NLP), and other domains. It aims at embedding augmented versions of the same sample close to each other while trying to push away embeddings from different samples. This paper provides an extensive review of self-supervised methods that follow the contrastive approach. The work explains commonly used pretext tasks in a contrastive learning setup, followed by different architectures that have been proposed so far. Next, we present a performance comparison of different methods for multiple downstream tasks such as image classification, object detection, and action recognition. Finally, we conclude with the limitations of the current methods and the need for further techniques and future directions to make meaningful progress.},
DOI = {10.3390/technologies9010002}
}

@InProceedings{TripletLoss,
author = {Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
title = {FaceNet: A Unified Embedding for Face Recognition and Clustering},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2015}
}

@InProceedings{SigLIP,
    author    = {Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
    title     = {Sigmoid Loss for Language Image Pre-Training},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2023},
    pages     = {11975-11986}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% More Related %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@ARTICLE{PCNSurvey,
  author={Tesema, Keneni W. and Hill, Lyndon and Jones, Mark W. and Ahmad, Muneeb I. and Tam, Gary K.L.},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Point Cloud Completion: A Survey}, 
  year={2024},
  volume={30},
  number={10},
  pages={6880-6899},
  doi={10.1109/TVCG.2023.3344935}
}

@article{GANPCC1,
  author       = {Swaminathan Gurumurthy and
                  Shubham Agrawal},
  title        = {High Fidelity Semantic Shape Completion for Point Clouds using Latent
                  Optimization},
  journal      = {CoRR},
  volume       = {abs/1807.03407},
  year         = {2018},
  eprinttype    = {arXiv},
  eprint       = {1807.03407},
  timestamp    = {Mon, 13 Aug 2018 16:46:00 +0200},
}

@article{GANUPCC,
  author       = {Xuelin Chen and
                  Baoquan Chen and
                  Niloy J. Mitra},
  title        = {Unpaired Point Cloud Completion on Real Scans using Adversarial Training},
  journal      = {CoRR},
  volume       = {abs/1904.00069},
  year         = {2019},
  eprinttype    = {arXiv},
  eprint       = {1904.00069},
  timestamp    = {Wed, 24 Apr 2019 12:21:25 +0200},
}

@inproceedings{GAN,
author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
title = {Generative adversarial nets},
year = {2014},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to ½ everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2},
pages = {2672–2680},
numpages = {9},
location = {Montreal, Canada},
series = {NIPS'14}
}

@inproceedings{NeuralPull,
    title = {Neural-Pull: Learning Signed Distance Functions from Point Clouds by Learning to Pull Space onto Surfaces},
    author = {Baorui, Ma and Zhizhong, Han and Yu-Shen, Liu and Matthias, Zwicker},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2021}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Eval %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@techreport{ShapeNet,
  title       = {{ShapeNet: An Information-Rich 3D Model Repository}},
  author      = {Chang, Angel X. and Funkhouser, Thomas and Guibas, Leonidas and Hanrahan, Pat and Huang, Qixing and Li, Zimo and Savarese, Silvio and Savva, Manolis and Song, Shuran and Su, Hao and Xiao, Jianxiong and Yi, Li and Yu, Fisher},
  number      = {arXiv:1512.03012 [cs.GR]},
  institution = {Stanford University --- Princeton University --- Toyota Technological Institute at Chicago},
  year        = {2015}
}

@Article{BuildingPCC,
AUTHOR = {Gao, W. and Peters, R. and Stoter, J.},
TITLE = {Building-PCC: Building Point Cloud Completion Benchmarks},
JOURNAL = {ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
VOLUME = {X-4/W5-2024},
YEAR = {2024},
PAGES = {179--186},
DOI = {10.5194/isprs-annals-X-4-W5-2024-179-2024}
}

@inproceedings{FiLM,
    title={SA-ConvONet: Sign-Agnostic Optimization of Convolutional Occupancy Networks},
    author={Tang, Jiapeng and Lei, Jiabao and Xu, Dan and Ma, Feiying and Jia, Kui and Zhang, Lei},
    booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
    year={2021}
}

@INPROCEEDINGS{PointNet,
  author={Charles, R. Qi and Su, Hao and Kaichun, Mo and Guibas, Leonidas J.},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation}, 
  year={2017},
  volume={},
  number={},
  pages={77-85},
  doi={10.1109/CVPR.2017.16}
}

@article{Adam,
  title={Adam: A Method for Stochastic Optimization},
  author={Diederik P. Kingma and Jimmy Ba},
  journal={CoRR},
  year={2014},
  volume={abs/1412.6980},
}

@article{ExpLR,
  author       = {Zhiyuan Li and
                  Sanjeev Arora},
  title        = {An Exponential Learning Rate Schedule for Deep Learning},
  journal      = {CoRR},
  volume       = {abs/1910.07454},
  year         = {2019},
  eprinttype    = {arXiv},
  eprint       = {1910.07454},
  timestamp    = {Mon, 25 Nov 2019 14:34:48 +0100},
}

@inproceedings{DCIkNN,
  title={Fast k-nearest neighbour search via {Dynamic Continuous Indexing}},
  author={Li, Ke and Malik, Jitendra},
  booktitle={International Conference on Machine Learning},
  pages={671--679},
  year={2016}
}

@inproceedings{AMSGrad,
  author       = {Sashank J. Reddi and
                  Satyen Kale and
                  Sanjiv Kumar},
  title        = {On the Convergence of Adam and Beyond},
  booktitle    = {6th International Conference on Learning Representations, {ICLR} 2018,
                  Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  publisher    = {OpenReview.net},
  year         = {2018},
  timestamp    = {Thu, 04 Apr 2019 13:20:09 +0200},
}

@inproceedings{CosLR,
  author       = {Ilya Loshchilov and
                  Frank Hutter},
  title        = {{SGDR:} Stochastic Gradient Descent with Warm Restarts},
  booktitle    = {5th International Conference on Learning Representations, {ICLR} 2017,
                  Toulon, France, April 24-26, 2017, Conference Track Proceedings},
  publisher    = {OpenReview.net},
  year         = {2017},
  timestamp    = {Thu, 25 Jul 2019 14:25:58 +0200},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Conclude %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@inproceedings{DDPM,
author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
title = {Denoising diffusion probabilistic models},
year = {2020},
isbn = {9781713829546},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.},
booktitle = {Proceedings of the 34th International Conference on Neural Information Processing Systems},
articleno = {574},
numpages = {12},
location = {Vancouver, BC, Canada},
series = {NIPS '20}
}

@InProceedings{PSF,
    author    = {Wu, Lemeng and Wang, Dilin and Gong, Chengyue and Liu, Xingchao and Xiong, Yunyang and Ranjan, Rakesh and Krishnamoorthi, Raghuraman and Chandra, Vikas and Liu, Qiang},
    title     = {Fast Point Cloud Generation With Straight Flows},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2023},
    pages     = {9445-9454}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Old Ones %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@techreport{Cas63,
  author = {de Casteljau, Paul},
  title = {Courbes et surfaces {\`a} p{\^o}les},
  year = {1963},
  institution = {A. Citro{\"e}n},
  address = {Paris},
}

@article{Bez67,
  author = {B{\'e}zier, Pierre},
  title = {D{\'e}finition num{\'e}rique des courbes et surfaces II},
  year = {1967},
  journal = {Automatisme},
  volume = {12},
}

@article{Boo62,
  author = {de Boor, Carl},
  title = {Bicubic Spline Interpolation},
  year = {1962},
  journal = {Journal of Mathematical Physics},
  volume = {41},
  number = {3},
}

@article{GR74,
  author = {Gordon, William J. and Riesenfeld, Richard F.},
  title = {B-Spline Curves and Surfaces},
  year = {1974},
  journal = {Computer Aided Geometric Design},
  volume = {167},
  publisher = {Academic Press New York},
}

@phdthesis{Ver75,
  author = {Versprille, Kenneth James},
  title = {Computer-Aided Design Applications of the Rational B-Spline Approximation Form},
  year = {1975},
  publisher = {Syracuse University},
  address = {Syracuse University},
}

@article{SZB+03,
  author = {Sederberg, Thomas W. and Zheng, Jianmin and Bakenov, Almaz and Nasri, Ahmad},
  title = {T-Splines and T-NURCCs},
  year = {2003},
  journal = {ACM Transactions on Graphics},
  volume = {22},
  number = {3},
  publisher = {ACM},
}
