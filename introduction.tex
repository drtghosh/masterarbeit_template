\chapter{Introduction}\label{ch:introduction}
Reconstructing curved surfaces from point clouds is a well-studied problem in the field of computer graphics, as point clouds are widely used to represent 3D shapes due to the ease of obtaining point cloud data (via scanning). It refers to the process of converting a discrete set of points in 3D space to another representation for two-dimensional manifolds, such as a mesh or an implicit function. Such an underdetermined process is inherently uncertain. Moreover, often the captured 3D geometry is noisy and sparse or incomplete due to limited sensor resolution, viewing angle, and occlusion, leading to further uncertainty. It is crucial to reconstruct the incomplete 3D shape in its entirety for a better understanding of 3D shapes or scenes, and for various downstream tasks such as simulation, next-view planning, grasping, path planning, collision detection, and so on. 
\newline

Many learning-based methods~\cite{PCN, PoinTr, PointAttN, P2C, VarPCN, PCNSkip, Snowflake} implemented point cloud completion in various settings for a given incomplete point cloud by predicting the missing points or the complete point cloud. Such a deterministic one-to-one mapping is restrictive in terms of diverse completion since one incomplete shape can be completed in many different ways, leading to various geometries. To address this issue, certain works have introduced different generative model-based strategies~\cite{HyperPocket, CGAN, PCCIMLE, EBResLT} to generate multiple complete point clouds for a given partial point cloud as input. Among such methods, only one~\cite{EBResLT} provided an uncertainty map from the multiple clouds generated for a partial input cloud by performing multiple inferences and naively computing the mean and variance for each point without any assumption about their correspondences, following the approach suggested in~\cite{UncertDeepL}. In such a procedure, we do not know any one-to-one mapping of individual points between the generated clouds. Also, such methods cannot restrict producing a complete cloud in a manner where each point corresponds to a particular position in the 3D shape. This might lead to completely unrelated points matched together, resulting in erroneous mean and variance estimations.
\\
To find a more meaningful matching between generated clouds, we posed this as a linear assignment problem with a suitable cost function (e.g., Euclidean distance). We selected one of the generated complete clouds and identified one-to-one mappings with points in the other complete clouds. We then used the resulting matching to compute the mean and variance estimations of the predicted complete point cloud. This simple matching can be extended to any generative completion methods that can produce multiple possible predictions. We can then utilize existing methods of surface reconstruction from unoriented point clouds to obtain corresponding surfaces and empirically estimate the average position of the surface along with its associated uncertainty.
\newline
 
Extensive work has been done in terms of reconstructing surfaces from point clouds, as discussed in~\cite{SurveyReconPC1, SurveyReconPC2}. While some methods reconstruct the surface as a mesh, others compute an implicit function whose zero level-set represents the surface. Poisson Surface Reconstruction (PSR)~\cite{PSR} has been the most popular method for surface reconstruction from an oriented point cloud. Multiple works have further improved upon PSR either by using screening~\cite{ScreenedPSR} and envelope constraints~\cite{PSREnv}, or by reformulating the classic Poisson solver in a differentiable way~\cite{DiffPSR}. Parallelly, numerous learning-based methods~\cite{IGR, SIREN, IDF} have been developed for surface reconstruction using implicit neural representation from oriented point clouds. Neural Poisson Surface Reconstruction method~\cite{nPSR} incorporated a neural network (NN) based on the Fourier neural operator to approximate PSR, combining the robustness of the traditional method and the generalizability of NNs. Similarly, standard approaches to producing a mesh from unoriented point clouds~\cite{iPSR, ParamGauss} have been accompanied by even more extensive learning-based methods yielding implicit representations of the surface~\cite{SAL, PredPrior, SparseSurf, POCO, P2Surf, DiGS, SALD, NeuralHessian}. However, none of the above methods have touched upon the aspect of the inherent uncertainty of such reconstruction methods for curved surfaces.
\newline

The authors of~\cite{GPIS} introduced a probabilistic formulation for modelling the implicit representation of the surface using a Gaussian Process (GP) with a covariance function equivalent to the thin plate spline energy regularizer. The covariance function of the GP can be adapted according to the regularizer used. In such methods termed Gaussian Process Implicit Surfaces (GPIS), the implicit function is assumed to follow a Gaussian distribution with some prior assumption about the mean and covariance. One can compute the posterior distribution quite easily given the observed points, utilizing the properties of the Gaussian distribution. One can then reconstruct the surface by extracting the zero level set of the posterior mean along with the uncertainty of the reconstructed surface, quantified by the posterior covariance. The same idea has been adapted for several tasks with uncertainty, such as shape estimation for grasping~\cite{GPISGrasp}, view planning~\cite{GPISView}, and segmentation~\cite{GPRSeg}. 
\\
Since GPs are better suited to quantify the uncertainty of a real-valued function (regression model), other approaches implemented the above idea with distance functions over a given space that map any query point to the distance to its closest point on the surface~\cite{logGPIS, geoPriorGPIS, GPDF, onlineGPIS, onlinePriorGPIS} instead of occupancy maps~\cite{GPOccMap}. Unfortunately, most of these methods are computationally expensive due to the cubic complexity of Gaussian process posterior calculation. Alternative methods proposed to resolve this downside of GP by introducing a mixture of local GPs ~\cite{mixGPOccMap, locGPOccMap, onlineGPIS} or by using a simplified prior for the mean function of GP~\cite{onlinePriorGPIS, GMMGP}. Further works used normal information to compute an interpolated gradient vector field and model it as a vector-valued Gaussian process, and use a PDE solver to recover the distribution over the scalar distance field~\cite{SPSR, NeuralSPSR}.
\newline

All these methods either depend on the availability of distance function values for supervision or are based on the assumption that we have access to oriented point clouds. But exact normal information is often not available for 3D data captured via scanning. Moreover, accurate distance values are quite difficult to acquire for proper supervision. A previous work~\cite{UncPCS} provided a likelihood map estimation for a point cloud with no other information (normal information, distance function values) available as a weighted sum of linear extrapolators computed from least squares fits of neighbouring points. Furthermore, the authors of~\cite{UncPCS} computed a confidence map that quantifies the confidence of local estimates by aggregating the confidences of individual extrapolators, similar to the likelihood map. 
\\
However, in reality, the data observed from scans of 3D objects only contains positions (3D coordinates with respect to the scanner) of the points on the surface. Due to resource and viewpoint constraints or occlusion (resulting from a complex geometric structure), the observed set of points is also not comprehensive and may exclude some regions. Even when the normal information can be obtained, it is not reliable enough for downstream tasks. Therefore, in this thesis, we consider a setting where only an unoriented point cloud is available as an input, which is often incomplete or sparse. To the best of our knowledge, no previous work has tried to perform uncertainty quantification for surface reconstruction under the above circumstances. An earlier work~\cite{geoPriorGPIS} has provided a Gaussian process-based uncertainty quantification for surface reconstruction from partial surface observations by assuming a geometric prior for each object; however, the method utilized surface normals to achieve its performance. Moreover, our goal is to learn and use the surface reconstruction uncertainty as a prior itself rather than using an assumed prior, which can subsequently inform the decisions of downstream tasks.
\newline

We propose three different approaches to solve the described problem. Firstly, we attempt to generate multiple possible completions of a given incomplete point cloud, combining deep learning-based point cloud completion methods and random generation to empirically quantify the uncertainty. The second approach was to produce multiple implicit representations consistent with our input cloud and empirically estimate the mean and variance of the implicit function values at any points in space, both on and around the surface. Finally, motivated by the well-established usage of Gaussian processes in uncertainty quantification for regression tasks, we try to model the distribution over the implicit function as a Gaussian process conditioned on the input partial cloud. 
\newline

This thesis is structured as follows: we begin by discussing important concepts required as background for implementing our proposed methods in Chapter~\ref{ch:background}, and then a review of the related works in Chapter~\ref{ch:related-work}. In Chapter~\ref{ch:methods}, the main contribution of this thesis is presented, where the methods proposed above are explained in detail. In the following chapter (Chapter~\ref{ch:evaluation}), we evaluate our approaches with qualitative and quantitative comparisons. We also present examples with satisfactory results and discuss the limitations of the approaches for specific cases. Finally, Chapter~\ref{ch:conclusion} provides an overview of our work and an outlook on potential future work.